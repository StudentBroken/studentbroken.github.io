<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tuteur Académique IA</title>
    <style>
        :root {
            --user-color: #007bff;
            --tutor-color: #f1f1f1;
            --background-color: #ffffff;
            --text-color: #212529;
            --border-color: #dee2e6;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            display: flex;
            flex-direction: column;
            height: 100vh;
            background-color: var(--background-color);
            color: var(--text-color);
        }
        #header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.5rem;
            border-bottom: 1px solid var(--border-color);
            background-color: var(--background-color);
            flex-shrink: 0;
        }
        #header h1 { font-size: 1.25rem; margin: 0; }
        #status { font-size: 0.8rem; color: #6c757d; }
        .ai-mode-toggle { display: flex; align-items: center; gap: 0.5rem; }
        .switch { position: relative; display: inline-block; width: 100px; height: 34px; }
        .switch input { opacity: 0; width: 0; height: 0; }
        .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #ccc; transition: .4s; border-radius: 34px; }
        .slider:before { position: absolute; content: ""; height: 26px; width: 26px; left: 4px; bottom: 4px; background-color: white; transition: .4s; border-radius: 50%; }
        input:checked + .slider { background-color: var(--user-color); }
        input:checked + .slider:before { transform: translateX(66px); }
        .slider:after { content: 'Tuteur'; color: white; display: block; position: absolute; transform: translate(-50%,-50%); top: 50%; left: 30%; font-size: 12px; }
        input:checked + .slider:after { content: 'Analyste'; left: 70%;}
        #chat-container {
            flex-grow: 1;
            padding: 1rem 1.5rem;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .message { padding: 10px 18px; border-radius: 22px; max-width: 80%; line-height: 1.5; word-wrap: break-word; }
        .user-message { background-color: var(--user-color); color: white; align-self: flex-end; }
        .tutor-message { background-color: var(--tutor-color); color: var(--text-color); align-self: flex-start; }
        .tutor-message.loading::after { content: '...'; display: inline-block; animation: dots 1.5s infinite steps(3, end); }
        @keyframes dots { 0% { content: '.'; } 33% { content: '..'; } 66% { content: '...'; } }
        #input-area {
            display: flex;
            padding: 1rem 1.5rem;
            border-top: 1px solid var(--border-color);
            background-color: rgba(255,255,255,0.8);
            backdrop-filter: blur(10px);
        }
        #user-input {
            flex-grow: 1;
            border: 1px solid #ccc;
            border-radius: 22px;
            padding: 10px 18px;
            font-size: 1rem;
            resize: none;
        }
        #send-btn {
            background-color: var(--user-color);
            color: white; border: none; border-radius: 50%;
            width: 44px; height: 44px; margin-left: 10px;
            font-size: 1.5rem; cursor: pointer; transition: background-color 0.2s;
            display: flex; align-items: center; justify-content: center;
        }
        #send-btn:disabled { background-color: #a0a0a0; cursor: not-allowed; }
        #debug-panel {
            position: fixed;
            bottom: 0; left: 0; right: 0;
            background-color: #111;
            color: #0f0;
            font-family: 'Courier New', Courier, monospace;
            font-size: 12px;
            max-height: 25vh;
            overflow-y: auto;
            border-top: 2px solid var(--user-color);
            z-index: 1000;
            transition: transform 0.3s ease-in-out;
            transform: translateY(100%);
        }
        #debug-panel.visible { transform: translateY(calc(100% - 30px)); }
        #debug-panel:hover { transform: translateY(0); }
        #debug-header { padding: 5px 10px; background-color: #333; cursor: pointer; }
        #debug-log { padding: 10px; white-space: pre-wrap; }
    </style>
</head>
<body>

    <div id="header">
        <div><h1>Tuteur Académique IA</h1><div id="status">Chargement du modèle IA...</div></div>
        <div class="ai-mode-toggle"><label class="switch"><input type="checkbox" id="ai-mode-checkbox"><span class="slider"></span></label></div>
    </div>
    <div id="chat-container"></div>
    <div id="input-area"><input type="text" id="user-input" placeholder="Posez une question sur vos résultats..." disabled><button id="send-btn" disabled>&#9658;</button></div>
    <div id="debug-panel"><div id="debug-header">Journal de Débogage &#9660;</div><div id="debug-log"></div></div>

    <!-- *** THE ONLY CHANGE IS GOING BACK TO A SINGLE type="module" SCRIPT *** -->
    <script type="module">
        // 1. Import the library correctly as a module.
        // The browser will wait for this line to finish before running any other code in this block.
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';

        // 2. Configure the library immediately after it's imported.
        // This solves the original "race condition" problem.
        env.allowRemoteModels = true;
        
        // 3. The rest of your application code is here.
        const status = document.getElementById('status');
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const aiModeCheckbox = document.getElementById('ai-mode-checkbox');
        const debugPanel = document.getElementById('debug-panel');
        const debugHeader = document.getElementById('debug-header');
        const debugLog = document.getElementById('debug-log');

        let tutorPipeline = null;
        let studentDataContext = '';
        let currentAiMode = 'tuteur';

        const PROMPT_TUTEUR = `Tu es un tuteur académique expert, amical et encourageant. Ton rôle est d'analyser les données scolaires de l'étudiant fournies ci-dessous et de répondre à ses questions de manière bienveillante et pédagogique. Explique les concepts simplement et aide l'étudiant à comprendre ses forces et ses faiblesses. Base toutes tes réponses STRICTEMENT sur les données fournies.`;
        const PROMPT_ANALYSTE = `Tu es un moteur d'analyse de données purement logique et objectif. Ton seul rôle est d'interpréter les données brutes suivantes de manière factuelle. N'utilise aucun langage émotionnel, d'opinion ou d'encouragement. Fournis des faits, des statistiques, des tendances et des déductions logiques basées uniquement sur les données. Sois concis et précis.`;

        function logToDebug(message) {
            const timestamp = new Date().toLocaleTimeString();
            debugLog.innerHTML += `[${timestamp}] ${message}\n`;
            debugLog.scrollTop = debugLog.scrollHeight;
        }

        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', `${sender}-message`);
            messageDiv.textContent = text;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return messageDiv;
        }
        
        function formatDataForSLM(rawData, analysisData) {
            logToDebug("Début de la conversion des données en texte...");
            let summary = `DONNÉES BRUTES DE L'ÉTUDIANT:\n`;
            if (rawData?.nom) summary += `Nom: ${rawData.nom}\n`;

            ['etape1', 'etape2'].forEach(etape => {
                if (rawData[etape] && rawData[etape].length > 0) {
                    summary += `\n--- RÉSULTATS ${etape.toUpperCase()} ---\n`;
                    rawData[etape].forEach(subject => {
                        summary += `Sujet: ${subject.name} (${subject.code})\n`;
                        subject.competencies.forEach(comp => {
                            comp.assignments.forEach(assign => {
                                if (assign.result) {
                                    summary += `- Travail: "${assign.work}", Résultat: ${assign.result}\n`;
                                }
                            });
                        });
                    });
                }
            });

            if (analysisData) {
                summary += `\n\nANALYSE PRÉDICTIVE ET STATISTIQUES:\n`;
                if(analysisData.globalAverage) summary += `- Moyenne générale (connue): ${analysisData.globalAverage.toFixed(2)}%\n`;
                if(analysisData.burnoutRiskScore) summary += `- Score de risque de burnout: ${analysisData.burnoutRiskScore.toFixed(0)}/100\n`;
                if(analysisData.globalConsistencyScore) summary += `- Indice de consistance globale: ${analysisData.globalConsistencyScore.toFixed(0)}/100\n`;
                if(analysisData.predictions?.global?.p50) summary += `- Prédiction de la moyenne finale (Médiane P50): ${analysisData.predictions.global.p50.toFixed(2)}%\n`;
            }
            logToDebug(`Conversion terminée. Longueur du contexte: ${summary.length} caractères.`);
            return summary;
        }

        async function handleSend() {
            const query = userInput.value.trim();
            if (query === '' || !tutorPipeline) return;

            addMessage(query, 'user');
            userInput.value = '';
            logToDebug(`Question de l'utilisateur: "${query}"`);
            
            const loadingMessage = addMessage("Réflexion en cours...", 'tutor');
            loadingMessage.classList.add('loading');

            const systemPrompt = currentAiMode === 'tuteur' ? PROMPT_TUTEUR : PROMPT_ANALYSTE;
            logToDebug(`Mode IA actif: ${currentAiMode}. Construction du prompt...`);

            const fullPrompt = `<|system|>\n${systemPrompt}\n\n--- DONNÉES DE L'ÉTUDIANT ---\n${studentDataContext}\n--- FIN DES DONNÉES ---\n</s>\n<|user|>\n${query}\n</s>\n<|assistant|>`;
            
            logToDebug("Prompt envoyé au modèle IA.");

            try {
                const result = await tutorPipeline(fullPrompt, {
                    max_new_tokens: 300,
                    do_sample: true,
                    temperature: 0.7,
                    top_k: 50,
                });
                
                const responseText = result[0].generated_text.split('<|assistant|>').pop().trim();
                loadingMessage.textContent = responseText;
                loadingMessage.classList.remove('loading');
                logToDebug("Réponse IA reçue et affichée.");

            } catch (e) {
                const errorMsg = "Désolé, une erreur est survenue. Veuillez réessayer.";
                loadingMessage.textContent = errorMsg;
                loadingMessage.classList.remove('loading');
                logToDebug(`ERREUR: ${e.message}`);
                console.error(e);
            }
        }

        async function main() {
            logToDebug("Initialisation du Tuteur IA.");
            try {
                const rawData = JSON.parse(localStorage.getItem('mbsData'));
                const analysisData = JSON.parse(localStorage.getItem('mbsProjectionCache'));
                
                if (!rawData || !rawData.valid) {
                    status.textContent = "Données 'mbsData' introuvables.";
                    logToDebug("ERREUR: 'mbsData' non valide ou introuvable dans le Local Storage.");
                    return;
                }
                logToDebug("'mbsData' et 'mbsProjectionCache' chargés avec succès.");
                studentDataContext = formatDataForSLM(rawData, analysisData);

                status.textContent = 'Chargement du modèle IA (peut prendre un moment)...';
                logToDebug("Téléchargement du modèle: Xenova/flan-t5-small");
                
                // Use 'text2text-generation' for T5 models
                tutorPipeline = await pipeline('text2text-generation', 'Xenova/flan-t5-small');
                
                status.textContent = `Bonjour, ${rawData.nom}! Je suis prêt.`;
                logToDebug("Modèle IA chargé et prêt.");
                
                userInput.disabled = false;
                sendBtn.disabled = false;
                addMessage("J'ai analysé vos données académiques. Comment puis-je vous aider aujourd'hui ?", 'tutor');

            } catch (e) {
                status.textContent = "Échec du chargement. Veuillez rafraîchir la page.";
                logToDebug(`ERREUR critique à l'initialisation: ${e.message}`);
                console.error(e);
            }
        }

        sendBtn.addEventListener('click', handleSend);
        userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') handleSend(); });
        aiModeCheckbox.addEventListener('change', (e) => {
            currentAiMode = e.target.checked ? 'analyste' : 'tuteur';
            logToDebug(`Changement de mode IA -> ${currentAiMode.toUpperCase()}`);
        });
        debugHeader.addEventListener('click', () => debugPanel.classList.toggle('visible'));

        main();
    </script>
</body>
</html>
