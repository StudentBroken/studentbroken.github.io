<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tuteur Académique IA (V3 - Stable)</title>
    <!-- The CSS and HTML structure is unchanged, so it is omitted here for brevity -->
    <style>
        :root{--user-color:#007bff;--tutor-color:#f1f1f1;--background-color:#ffffff;--text-color:#212529;--border-color:#dee2e6}body{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial,sans-serif;margin:0;display:flex;flex-direction:column;height:100vh;background-color:var(--background-color);color:var(--text-color)}#header{display:flex;justify-content:space-between;align-items:center;padding:.75rem 1.5rem;border-bottom:1px solid var(--border-color);background-color:var(--background-color);flex-shrink:0}#header h1{font-size:1.25rem;margin:0}#status{font-size:.8rem;color:#6c757d}.ai-mode-toggle{display:flex;align-items:center;gap:.5rem}.switch{position:relative;display:inline-block;width:100px;height:34px}.switch input{opacity:0;width:0;height:0}.slider{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#ccc;transition:.4s;border-radius:34px}.slider:before{position:absolute;content:"";height:26px;width:26px;left:4px;bottom:4px;background-color:white;transition:.4s;border-radius:50%}input:checked+.slider{background-color:var(--user-color)}input:checked+.slider:before{transform:translateX(66px)}.slider:after{content:'Tuteur';color:white;display:block;position:absolute;transform:translate(-50%,-50%);top:50%;left:30%;font-size:12px}input:checked+.slider:after{content:'Analyste';left:70%}#chat-container{flex-grow:1;padding:1rem 1.5rem;overflow-y:auto;display:flex;flex-direction:column;gap:1rem}.message{padding:10px 18px;border-radius:22px;max-width:80%;line-height:1.5;word-wrap:break-word}.user-message{background-color:var(--user-color);color:white;align-self:flex-end}.tutor-message{background-color:var(--tutor-color);color:var(--text-color);align-self:flex-start}.tutor-message.loading::after{content:'...';display:inline-block;animation:dots 1.5s infinite steps(3,end)}@keyframes dots{0%{content:'.'}33%{content:'..'}66%{content:'...'}}#input-area{display:flex;padding:1rem 1.5rem;border-top:1px solid var(--border-color);background-color:rgba(255,255,255,.8);backdrop-filter:blur(10px)}#user-input{flex-grow:1;border:1px solid #ccc;border-radius:22px;padding:10px 18px;font-size:1rem;resize:none}#send-btn{background-color:var(--user-color);color:white;border:none;border-radius:50%;width:44px;height:44px;margin-left:10px;font-size:1.5rem;cursor:pointer;transition:background-color .2s;display:flex;align-items:center;justify-content:center}#send-btn:disabled{background-color:#a0a0a0;cursor:not-allowed}#debug-panel{position:fixed;bottom:0;left:0;right:0;background-color:#111;color:#0f0;font-family:'Courier New',Courier,monospace;font-size:12px;max-height:25vh;overflow-y:auto;border-top:2px solid var(--user-color);z-index:1000;transition:transform .3s ease-in-out;transform:translateY(100%)}#debug-panel.visible{transform:translateY(calc(100% - 30px))}#debug-panel:hover{transform:translateY(0)}#debug-header{padding:5px 10px;background-color:#333;cursor:pointer}#debug-log{padding:10px;white-space:pre-wrap}
    </style>
</head>
<body>
    <div id="header">
        <div><h1>Tuteur Académique IA (V3)</h1><div id="status">Chargement...</div></div>
        <div class="ai-mode-toggle"><label class="switch"><input type="checkbox" id="ai-mode-checkbox"><span class="slider"></span></label></div>
    </div>
    <div id="chat-container"></div>
    <div id="input-area"><input type="text" id="user-input" placeholder="Posez une question..." disabled><button id="send-btn" disabled>&#9658;</button></div>
    <div id="debug-panel"><div id="debug-header">Journal de Débogage &#9660;</div><div id="debug-log"></div></div>

    <script type="module">
        // --- THIS IS THE NEW, ROBUST LOADING SCRIPT ---
        import { pipeline, AutoTokenizer, AutoModelForSeq2SeqLM } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';
        
        const status = document.getElementById('status');
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const aiModeCheckbox = document.getElementById('ai-mode-checkbox');
        const debugLog = document.getElementById('debug-log');
        const debugHeader = document.getElementById('debug-header');

        let tutorPipeline = null;
        let studentDataContext = '';
        let currentAiMode = 'tuteur';

        const PROMPT_TUTEUR = `Tu es un tuteur académique expert, amical et encourageant...`; // (content is the same as before)
        const PROMPT_ANALYSTE = `Tu es un moteur d'analyse de données purement logique et objectif...`; // (content is the same as before)

        function logToDebug(message) {
            const timestamp = new Date().toLocaleTimeString();
            debugLog.innerHTML += `[${timestamp}] ${message}\n`;
            debugLog.scrollTop = debugLog.scrollHeight;
        }

        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', `${sender}-message`);
            messageDiv.textContent = text;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return messageDiv;
        }
        
        function formatDataForSLM(rawData, analysisData) {
            logToDebug("Formatting data into text context...");
            let summary = `DONNÉES BRUTES DE L'ÉTUDIANT:\n`;
            if (rawData?.nom) summary += `Nom: ${rawData.nom}\n`;
            ['etape1', 'etape2'].forEach(etape => {
                if (rawData[etape] && rawData[etape].length > 0) {
                    summary += `\n--- RÉSULTATS ${etape.toUpperCase()} ---\n`;
                    rawData[etape].forEach(subject => {
                        summary += `Sujet: ${subject.name} (${subject.code})\n`;
                        subject.competencies.forEach(comp => {
                            comp.assignments.forEach(assign => {
                                if (assign.result) summary += `- Travail: "${assign.work}", Résultat: ${assign.result}\n`;
                            });
                        });
                    });
                }
            });
            if (analysisData) {
                summary += `\n\nANALYSE PRÉDICTIVE ET STATISTIQUES:\n`;
                if(analysisData.globalAverage) summary += `- Moyenne générale (connue): ${analysisData.globalAverage.toFixed(2)}%\n`;
                if(analysisData.burnoutRiskScore) summary += `- Score de risque de burnout: ${analysisData.burnoutRiskScore.toFixed(0)}/100\n`;
                if(analysisData.globalConsistencyScore) summary += `- Indice de consistance globale: ${analysisData.globalConsistencyScore.toFixed(0)}/100\n`;
                if(analysisData.predictions?.global?.p50) summary += `- Prédiction de la moyenne finale (Médiane P50): ${analysisData.predictions.global.p50.toFixed(2)}%\n`;
            }
            logToDebug(`Context formatting complete. Length: ${summary.length}`);
            return summary;
        }

        async function handleSend() {
            const query = userInput.value.trim();
            if (query === '' || !tutorPipeline) return;
            addMessage(query, 'user');
            userInput.value = '';
            
            const loadingMessage = addMessage("Réflexion en cours...", 'tutor');
            loadingMessage.classList.add('loading');
            
            const systemPrompt = currentAiMode === 'tuteur' ? PROMPT_TUTEUR : PROMPT_ANALYSTE;
            const fullPrompt = `${systemPrompt}\n\n--- DONNÉES DE L'ÉTUDIANT ---\n${studentDataContext}\n--- FIN DES DONNÉES ---\nQuestion: ${query}`;
            
            try {
                const result = await tutorPipeline(fullPrompt, {
                    max_new_tokens: 300,
                    do_sample: true,
                    temperature: 0.7,
                    top_k: 50,
                });
                loadingMessage.textContent = result[0].generated_text;
                loadingMessage.classList.remove('loading');
            } catch (e) {
                loadingMessage.textContent = "Désolé, une erreur est survenue. Veuillez réessayer.";
                console.error("Inference error:", e);
            }
        }

        async function main() {
            logToDebug("Initializing Tutor AI (V3 - Manual Assembly)...");
            try {
                const rawData = JSON.parse(localStorage.getItem('mbsData'));
                const analysisData = JSON.parse(localStorage.getItem('mbsProjectionCache'));
                if (!rawData?.valid) {
                    status.textContent = "Données 'mbsData' introuvables.";
                    return;
                }
                studentDataContext = formatDataForSLM(rawData, analysisData);

                const model_id = 'Xenova/LaMini-Flan-T5-77M';
                const task = 'text2text-generation';
                
                // --- MANUAL ASSEMBLY PROCESS ---
                logToDebug(`STEP 1: Loading Tokenizer for model [${model_id}]`);
                status.textContent = "Étape 1/3 : Chargement du tokenizer...";
                const tokenizer = await AutoTokenizer.from_pretrained(model_id);
                logToDebug("Tokenizer loaded successfully.");

                logToDebug(`STEP 2: Loading Main Model for model [${model_id}]`);
                status.textContent = "Étape 2/3 : Chargement du modèle principal (peut être long)...";
                const model = await AutoModelForSeq2SeqLM.from_pretrained(model_id, {
                    progress_callback: (p) => {
                        status.textContent = `Étape 2/3 : Chargement... (${p.file.split('/').pop()}: ${Math.round(p.progress)}%)`;
                    }
                });
                logToDebug("Main model loaded successfully.");

                logToDebug("STEP 3: Assembling pipeline...");
                status.textContent = "Étape 3/3 : Assemblage du pipeline...";
                tutorPipeline = await pipeline(task, null, { // Pass null for model name
                    model: model,       // Provide the pre-loaded model
                    tokenizer: tokenizer // Provide the pre-loaded tokenizer
                });
                logToDebug("Pipeline assembled successfully! Tutor is ready.");
                
                status.textContent = `Bonjour, ${rawData.nom}! Je suis prêt.`;
                userInput.disabled = false;
                sendBtn.disabled = false;
                addMessage("J'ai analysé vos données académiques. Comment puis-je vous aider aujourd'hui ?", 'tutor');

            } catch (e) {
                status.textContent = "Une erreur critique est survenue. Veuillez rafraîchir la page.";
                logToDebug(`CRITICAL ERROR in main(): ${e.message}\n${e.stack}`);
                console.error(e);
            }
        }

        sendBtn.addEventListener('click', handleSend);
        userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') handleSend(); });
        aiModeCheckbox.addEventListener('change', (e) => {
            currentAiMode = e.target.checked ? 'analyste' : 'tuteur';
            logToDebug(`AI Mode changed -> ${currentAiMode.toUpperCase()}`);
        });
        debugHeader.addEventListener('click', () => document.getElementById('debug-panel').classList.toggle('visible'));

        main();
    </script>
</body>
</html>
